Development flow
-----------------
test sql with direct sql statements
load test file loads
load test outbound (outbound is a mock -- setTimeout)



data loading
-----------------

ingested - file is recorded to be "in the system", but data not loaded yet
loaded - rows have been loaded into the system, no transformations made
mapped - rows have been tagged with appropriate metadata, or transformed
    -- message functions applied and built out
queued / contacting - rows have been copied into appropriate contact queue tables
    -- last chance to cancel contacts
complete -- all contacts have been completed (whether errors were encountered we need to look into individual contact statuses)


messaging
------------------

-- message_functions table is a set of crude pointers to some other functions, either JS or MySQL.. ? (date, time, provider name, capitalization?)
-- as well as data (depends on the load map)

- the '{}' brackets mark the beginning of template mode.. or template language
- available template methods are:
    {data.[property]}
    {data.appointment_date|date|MM-DD-YYYY HH:MM:ss}
-You have an appointment on {data.appointment_date|date|MM-DD-YYYY HH:MM:ss} with {data.provider|name}
- {data.first_name|name} - capitalize the first letter, this is a proper name
- {data.last_name|name} - capitalize the first letter, this is a proper name
- {data.location|name} - capitalize the first letter, this is a proper name
- {company.name|name}
- {company.phone_number}

-- allow client/cust support to reset stage?

-- is this necessary if we're using json for the data field?
    -- this resolves the remote company data fields to fields mapped into the system
    -- this also allows companies to have several load maps to be active
        -- then each import (or data feed, or file) needs to reference a company_load_map.id
    -- this can also remove the requirement of having a "customer_xref" table..?

-- consider the limitation of the json column..
    -- maybe not a big deal
-- max size is server's max-allowed-packet size. defauly is 64MB

/*
- use MyIsam for logging or tables that might deadlock
- use table rotating for logs
- use gearman for caching inserts https://lornajane.net/posts/2011/using-persistent-storage-with-gearman

http://brian.moonspot.net/logging-with-mysql

create table messages_new like messages;
rename table messages to messages_history_2019041600001, messages_new to messages;


can query the system for tables that are messages_history_*: show tables like 'messages_history_%'

messages_history_2019041600001
messages_history_2019051600001
messages_history_2019061600001
etc

then union them for a complete poll of history
*/

/*
other features to be built out
-----------------
survey -- who responded the most, and who's most likely to respond to a survey
url shortener
auto reminders / cancellations
messae options - leave a different message on answering machine vs human

*/

/*
data ingest / file ingest
sources
-------------
    UI -> Excel-to-csv (self-inspection, mapping fields) ?
    excel-to-csv-to-s3
    UI -> CSV upload
    HTTPS->CSV->DB import
    csv-to-s3
    API
        api-to-s3
    Direct SQL
        push or pull
    Google Assistant?
    Google Calendar?
*/

/*
global_confirmation_templates
    #this is for confirmations and whatnot
    -- content for after clicking "confirm"/"cancel"/"reschedule"

data cleaning
    apply company rules based on field mapping
    filter duplicates

outbound rules
    auto responses
    days offset
*/

/*
-- wth is this?
flags
    id
    flag
    description
*/